{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in full dataset\n",
    "\n",
    "df = pd.read_csv(\"housing_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take subset of useful columns to be used in regression model to reduce clutter\n",
    "\n",
    "df_subset = df[['Date', 'Zip', 'InventorySeasonallyAdjusted_AllHomes',\n",
    "             'MedianListingPrice_AllHomes', 'PctOfHomesIncreasingInValues_AllHomes',\n",
    "             'ZHVI_AllHomes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_timeshift(zipcode, df, plots=False):\n",
    "\n",
    "    # filter full dataset for zipcode of interest, drop null rows\n",
    "    \n",
    "    df = df[df['Zip'] == zipcode]\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    # drop columns not used in regression model\n",
    "    \n",
    "    df_subset = df[['Date', 'Zip', 'InventorySeasonallyAdjusted_AllHomes',\n",
    "             'MedianListingPrice_AllHomes', 'PctOfHomesIncreasingInValues_AllHomes',\n",
    "             'ZHVI_AllHomes']]\n",
    "    \n",
    "    df_shift = df_subset.copy()\n",
    "    \n",
    "    df_date = df[['Date']]\n",
    "    \n",
    "    # set up lists that will contain correlation values for each time shift (1-6 months)\n",
    "    \n",
    "    season_corrs = []\n",
    "    zhvi_corrs = []\n",
    "    pct_corrs = []\n",
    "    \n",
    "    # loop through time shifts and append correlation values to lists\n",
    "    \n",
    "    for i in range(1, 7):\n",
    "        df_corrtest = df_subset.copy()\n",
    "        \n",
    "        df_corrtest['InventorySeasonallyAdjusted_AllHomes'] = df_corrtest['InventorySeasonallyAdjusted_AllHomes'].shift(i)\n",
    "        season_corrs.append(stats.pearsonr(df_corrtest['MedianListingPrice_AllHomes'][i:], \n",
    "                                           df_corrtest['InventorySeasonallyAdjusted_AllHomes'][i:]))\n",
    "        \n",
    "        df_corrtest['PctOfHomesIncreasingInValues_AllHomes'] = df_corrtest['PctOfHomesIncreasingInValues_AllHomes'].shift(i)\n",
    "        pct_corrs.append(stats.pearsonr(df_corrtest['MedianListingPrice_AllHomes'][i:], \n",
    "                                           df_corrtest['PctOfHomesIncreasingInValues_AllHomes'][i:]))\n",
    "        \n",
    "        df_corrtest['ZHVI_AllHomes'] = df_corrtest['ZHVI_AllHomes'].shift(i)\n",
    "        zhvi_corrs.append(stats.pearsonr(df_corrtest['MedianListingPrice_AllHomes'][i:], \n",
    "                                         df_corrtest['ZHVI_AllHomes'][i:]))\n",
    "        \n",
    "    # find the time shift for each predictor variable that results in best correlation\n",
    "    # best time shift will be equal to list index + 1 because of 0-indexing\n",
    "    # some correlations are negative, in which case the min correlation is found\n",
    "    \n",
    "    season_shift = season_corrs.index(min(season_corrs))+1\n",
    "    zhvi_shift = zhvi_corrs.index(max(zhvi_corrs))+1\n",
    "    pct_shift = pct_corrs.index(max(pct_corrs))+1\n",
    "    \n",
    "        \n",
    "    # shift dataset using optimal time shift settings found in previous step\n",
    "\n",
    "    df_subset['InventorySeasonallyAdjusted_AllHomes']=df_subset['InventorySeasonallyAdjusted_AllHomes'].shift(season_shift)\n",
    "    df_subset['ZHVI_AllHomes']=df_subset['ZHVI_AllHomes'].shift(zhvi_shift)\n",
    "    df_subset['PctOfHomesIncreasingInValues_AllHomes']=df_subset['PctOfHomesIncreasingInValues_AllHomes'].shift(pct_shift)\n",
    "    \n",
    "    # subset dataframe into X (independent variables) and Y (dependent variable)\n",
    "    # also need to account for the shifted variables to make sure dfX and dfY are the same length, so\n",
    "    # the first x number of rows are removed where x is the max time shift from the 3 independent variables\n",
    "    \n",
    "    dfX = df_subset[['InventorySeasonallyAdjusted_AllHomes', 'ZHVI_AllHomes' ,'PctOfHomesIncreasingInValues_AllHomes']][max(season_shift, zhvi_shift, pct_shift):]\n",
    "\n",
    "    dfY = df_subset[['MedianListingPrice_AllHomes']][max(season_shift, zhvi_shift, pct_shift):]\n",
    "    \n",
    "    # split into train/test\n",
    "    \n",
    "    length = len(dfX)\n",
    "    train = round(length*0.8)\n",
    "    test = length-train\n",
    "\n",
    "    dfX_train = dfX[:train]\n",
    "    dfX_test = dfX[-test:]\n",
    "    dfY_train = dfY[:train]\n",
    "    dfY_test = dfY[-test:]\n",
    "\n",
    "    \n",
    "    # regression model\n",
    "\n",
    "    regr=sm.OLS(dfY_train, dfX_train).fit()\n",
    "    \n",
    "    # predicted values\n",
    "\n",
    "    y_pred = regr.predict(dfX_test)\n",
    "    \n",
    "    dfY_test['predicted'] = y_pred\n",
    "    \n",
    "    # return predicted values for insertion into original dataframe\n",
    "    # indices are preserved for the eventual join\n",
    "\n",
    "    modeleval = pd.DataFrame()\n",
    "    modeleval['prediction'] = y_pred\n",
    "    modeleval['test'] = dfY_test['MedianListingPrice_AllHomes'].values\n",
    "    modeleval['zhvi'] = dfX_test['ZHVI_AllHomes']\n",
    "\n",
    "    # optional plot generator\n",
    "    \n",
    "    if plots==True:\n",
    "\n",
    "        modeleval = modeleval.join(df_date)\n",
    "        plt.scatter(x=modeleval['Date'], y=modeleval['prediction'], label='Predicted')\n",
    "        plt.plot(modeleval['Date'], modeleval['prediction'])\n",
    "        plt.scatter(x=modeleval['Date'], y=modeleval['test'], label='Actual')\n",
    "        plt.plot(modeleval['Date'], modeleval['test'])\n",
    "        plt.scatter(x=modeleval['Date'], y=modeleval['zhvi'], label='ZHVI')\n",
    "        plt.plot(modeleval['Date'], modeleval['zhvi'])\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('Home Price')\n",
    "        plt.title('Predicted home prices for zip code {}'.format(zipcode))\n",
    "        plt.grid(which='major', axis='both', alpha=0.5)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    # find max time shift from above\n",
    " \n",
    "    shift = max(season_shift, zhvi_shift, pct_shift)\n",
    "    \n",
    "    # shift all dependent variables using copy of original dataset\n",
    "    \n",
    "    dfX_shift = df_shift[['InventorySeasonallyAdjusted_AllHomes',  'ZHVI_AllHomes', 'PctOfHomesIncreasingInValues_AllHomes']][-shift:]\n",
    "    \n",
    "    # depending on max time shift, can use model to forecast into future months\n",
    "    # e.g. if variables for this zip code were shifted 6 months, we can take\n",
    "    # the last 6 months' worth of data in the original dataset and project\n",
    "    # 6 months into the future due to the time lag\n",
    "    \n",
    "    forecast_pred = regr.predict(dfX_shift)\n",
    "    \n",
    "    forecast_length = len(forecast_pred)\n",
    "    \n",
    "    # list of future dates that will be sliced depending on timeshift (6 months is maximum)\n",
    "    \n",
    "    date_str = ['2018-01-31', '2018-02-28', '2018-03-31', '2018-04-30', '2018-05-31', '2018-06-30']\n",
    "\n",
    "    # create forecast dataframe containing forecasted values for this zipcode\n",
    "    \n",
    "    forecast_df = pd.DataFrame()\n",
    "    forecast_df['Date'] = date_str[:shift]\n",
    "    forecast_df['Zip'] = zipcode\n",
    "    forecast_df['Predicted'] = forecast_pred.values\n",
    "\n",
    "\n",
    "    return dfY_test['predicted'], forecast_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005250446287934475\n",
      "0.01050089257586895\n",
      "0.015751338863803425\n",
      "0.0210017851517379\n",
      "0.026252231439672372\n",
      "0.03150267772760685\n",
      "0.03675312401554132\n",
      "0.0420035703034758\n",
      "0.04725401659141027\n",
      "0.052504462879344745\n",
      "0.05775490916727922\n",
      "0.0630053554552137\n",
      "0.06825580174314817\n",
      "0.07350624803108265\n",
      "0.07875669431901712\n",
      "0.0840071406069516\n",
      "0.08925758689488607\n",
      "0.09450803318282054\n",
      "0.09975847947075502\n",
      "0.10500892575868949\n",
      "0.11025937204662396\n",
      "0.11550981833455844\n",
      "0.12076026462249291\n",
      "0.1260107109104274\n",
      "0.13126115719836187\n",
      "0.13651160348629635\n",
      "0.14176204977423082\n",
      "0.1470124960621653\n",
      "0.15226294235009977\n",
      "0.15751338863803424\n",
      "0.16276383492596871\n",
      "0.1680142812139032\n",
      "0.17326472750183766\n",
      "0.17851517378977214\n",
      "0.1837656200777066\n",
      "0.18901606636564108\n",
      "0.19426651265357556\n",
      "0.19951695894151003\n",
      "0.2047674052294445\n",
      "0.21001785151737898\n",
      "0.21526829780531345\n",
      "0.22051874409324793\n",
      "0.2257691903811824\n",
      "0.23101963666911687\n",
      "0.23627008295705135\n",
      "0.24152052924498582\n",
      "0.2467709755329203\n",
      "0.2520214218208548\n",
      "0.25727186810878927\n",
      "0.26252231439672374\n",
      "0.2677727606846582\n",
      "0.2730232069725927\n",
      "0.27827365326052717\n",
      "0.28352409954846164\n",
      "0.2887745458363961\n",
      "0.2940249921243306\n",
      "0.29927543841226506\n",
      "0.30452588470019953\n",
      "0.309776330988134\n",
      "0.3150267772760685\n",
      "0.32027722356400296\n",
      "0.32552766985193743\n",
      "0.3307781161398719\n",
      "0.3360285624278064\n",
      "0.34127900871574085\n",
      "0.3465294550036753\n",
      "0.3517799012916098\n",
      "0.35703034757954427\n",
      "0.36228079386747875\n",
      "0.3675312401554132\n",
      "0.3727816864433477\n",
      "0.37803213273128217\n",
      "0.38328257901921664\n",
      "0.3885330253071511\n",
      "0.3937834715950856\n",
      "0.39903391788302006\n",
      "0.40428436417095454\n",
      "0.409534810458889\n",
      "0.4147852567468235\n",
      "0.42003570303475796\n",
      "0.42528614932269243\n",
      "0.4305365956106269\n",
      "0.4357870418985614\n",
      "0.44103748818649585\n",
      "0.4462879344744303\n",
      "0.4515383807623648\n",
      "0.4567888270502993\n",
      "0.46203927333823375\n",
      "0.4672897196261682\n",
      "0.4725401659141027\n",
      "0.47779061220203717\n",
      "0.48304105848997164\n",
      "0.4882915047779061\n",
      "0.4935419510658406\n",
      "0.49879239735377506\n",
      "0.5040428436417096\n",
      "0.5092932899296441\n",
      "0.5145437362175785\n",
      "0.519794182505513\n",
      "0.5250446287934475\n",
      "0.530295075081382\n",
      "0.5355455213693164\n",
      "0.5407959676572509\n",
      "0.5460464139451854\n",
      "0.5512968602331199\n",
      "0.5565473065210543\n",
      "0.5617977528089888\n",
      "0.5670481990969233\n",
      "0.5722986453848578\n",
      "0.5775490916727922\n",
      "0.5827995379607267\n",
      "0.5880499842486612\n",
      "0.5933004305365956\n",
      "0.5985508768245301\n",
      "0.6038013231124646\n",
      "0.6090517694003991\n",
      "0.6143022156883335\n",
      "0.619552661976268\n",
      "0.6248031082642025\n",
      "0.630053554552137\n",
      "0.6353040008400714\n",
      "0.6405544471280059\n",
      "0.6458048934159404\n",
      "0.6510553397038749\n",
      "0.6563057859918093\n",
      "0.6615562322797438\n",
      "0.6668066785676783\n",
      "0.6720571248556128\n",
      "0.6773075711435472\n",
      "0.6825580174314817\n",
      "0.6878084637194162\n",
      "0.6930589100073506\n",
      "0.6983093562952851\n",
      "0.7035598025832196\n",
      "0.7088102488711541\n",
      "0.7140606951590885\n",
      "0.719311141447023\n",
      "0.7245615877349575\n",
      "0.729812034022892\n",
      "0.7350624803108264\n",
      "0.7403129265987609\n",
      "0.7455633728866954\n",
      "0.7508138191746299\n",
      "0.7560642654625643\n",
      "0.7613147117504988\n",
      "0.7665651580384333\n",
      "0.7718156043263678\n",
      "0.7770660506143022\n",
      "0.7823164969022367\n",
      "0.7875669431901712\n",
      "0.7928173894781056\n",
      "0.7980678357660401\n",
      "0.8033182820539746\n",
      "0.8085687283419091\n",
      "0.8138191746298435\n",
      "0.819069620917778\n",
      "0.8243200672057125\n",
      "0.829570513493647\n",
      "0.8348209597815814\n",
      "0.8400714060695159\n",
      "0.8453218523574504\n",
      "0.8505722986453849\n",
      "0.8558227449333193\n",
      "0.8610731912212538\n",
      "0.8663236375091883\n",
      "0.8715740837971228\n",
      "0.8768245300850572\n",
      "0.8820749763729917\n",
      "0.8873254226609262\n",
      "0.8925758689488607\n",
      "0.8978263152367951\n",
      "0.9030767615247296\n",
      "0.9083272078126641\n",
      "0.9135776541005985\n",
      "0.918828100388533\n",
      "0.9240785466764675\n",
      "0.929328992964402\n",
      "0.9345794392523364\n",
      "0.9398298855402709\n",
      "0.9450803318282054\n",
      "0.9503307781161399\n",
      "0.9555812244040743\n",
      "0.9608316706920088\n",
      "0.9660821169799433\n",
      "0.9713325632678778\n",
      "0.9765830095558122\n",
      "0.9818334558437467\n",
      "0.9870839021316812\n",
      "0.9923343484196157\n",
      "0.9975847947075501\n"
     ]
    }
   ],
   "source": [
    "# code to loop through every unique zipcode in the original dataset, and create two new dataframes:\n",
    "# the original dataframe with a 'predicted' column for the portion of the original dataset that was set \n",
    "# aside for testing (20%), and a new dataframe with predictions that were forecasted/projected into\n",
    "# future months for each zipcode\n",
    "\n",
    "df_pred = pd.Series()\n",
    "df_forecast = pd.DataFrame()\n",
    "inc = 0\n",
    "\n",
    "# NOTE this cell can take ~30min or more to run\n",
    "\n",
    "for code in df['Zip'].unique():\n",
    "    try:\n",
    "        y, f = ols_timeshift(code, df_subset)\n",
    "        df_pred = pd.concat([df_pred, y])\n",
    "        df_forecast = pd.concat([df_forecast, f])\n",
    "        inc += 1\n",
    "    except:\n",
    "        print(code)\n",
    "        inc += 1\n",
    "    \n",
    "    # progress indicator\n",
    "        \n",
    "    if inc%100 == 0:\n",
    "        print(inc/len(df['Zip'].unique()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={0:\"Predicted\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'output_with_predictions.csv', index=False, header=True)\n",
    "df_forecast.to_csv(r'forecasted_predictions.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
